{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This notebook contains code focused on analysing features for the final model.\n",
    "**This is only for exploration.** See `features.py` for functionality related to extracting features for model implementation.\n",
    "\n",
    "First, read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../datasets/Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"../datasets/Test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' doctors hit campaign trail as race to medical council elections heats up https://t.co/iifdwb9v0w #homeopathy'\n",
      " ' is anybody going to the radio station tomorrow to see shawn? me and my friend may go but we would like to make new friends/meet there (:\\t'\n",
      " \" i just found out naruto didn't become the 5th hokage....\\t\"\n",
      " ' \"prince george reservist who died saturday just wanted to help people, his father tells @cbcnews http://t.co/riauzrjgre\"\\t'\n",
      " ' season in the sun versi nirvana rancak gak..slow rockkk...\\t'\n",
      " \" if i didnt have you i'd never see the sun. #mtvstars lady gaga\\t\"\n",
      " ' this is cute. #thisisus @nbcthisisus https://t.co/ndxqyl4gjk'\n",
      " ' today is the international day for the elimination of violence against women #orangetheworld #unitednations #unodc‚ä¶ https://t.co/uyqctttufj'\n",
      " ' \"in his first game back since april 14, david wright went 2-for-5 with a hr, bb and three r on monday. he also made two errors at 3b.\"\\t'\n",
      " ' josh hamilton flies out to center... we are going to the bottom of the 9th tied at 7! #nevereverquit\\t']\n",
      "[['', 'doctors', 'hit', 'campaign', 'trail', 'as', 'race', 'to', 'medical', 'council', 'elections', 'heats', 'up', 'httpstcoiifdwb9v0w', '#homeopathy'], ['', 'is', 'anybody', 'going', 'to', 'the', 'radio', 'station', 'tomorrow', 'to', 'see', 'shawn?', 'me', 'and', 'my', 'friend', 'may', 'go', 'but', 'we', 'would', 'like', 'to', 'make', 'new', 'friendsmeet', 'there', ''], ['', 'i', 'just', 'found', 'out', 'naruto', 'didnt', 'become', 'the', '5th', 'hokage'], ['', 'prince', 'george', 'reservist', 'who', 'died', 'saturday', 'just', 'wanted', 'to', 'help', 'people', 'his', 'father', 'tells', '@cbcnews', 'httptcoriauzrjgre'], ['', 'season', 'in', 'the', 'sun', 'versi', 'nirvana', 'rancak', 'gakslow', 'rockkk'], ['', 'if', 'i', 'didnt', 'have', 'you', 'id', 'never', 'see', 'the', 'sun', '#mtvstars', 'lady', 'gaga'], ['', 'this', 'is', 'cute', '#thisisus', '@nbcthisisus', 'httpstcondxqyl4gjk'], ['', 'today', 'is', 'the', 'international', 'day', 'for', 'the', 'elimination', 'of', 'violence', 'against', 'women', '#orangetheworld', '#unitednations', '#unodc‚ä¶', 'httpstcouyqctttufj'], ['', 'in', 'his', 'first', 'game', 'back', 'since', 'april', '14', 'david', 'wright', 'went', '2-for-5', 'with', 'a', 'hr', 'bb', 'and', 'three', 'r', 'on', 'monday', 'he', 'also', 'made', 'two', 'errors', 'at', '3b'], ['', 'josh', 'hamilton', 'flies', 'out', 'to', 'center', 'we', 'are', 'going', 'to', 'the', 'bottom', 'of', 'the', '9th', 'tied', 'at', '7!', '#nevereverquit']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tweets = train_data[['text']].values[:, 0]\n",
    "\n",
    "# split by spaces first (removing extraneous punctuation)\n",
    "tweet_word_lists = [re.sub(r'[\".,/\\\\(\\'):;\\t]||\\t', \"\", x).split(\" \") for x in tweets];\n",
    "\n",
    "# print the head of both lists just to check that it worked\n",
    "print(tweets[:10])\n",
    "print(tweet_word_lists[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TF-IDF\n",
    "The TF-IDF will identify the most important words in the tweet relative to the other tweets (helps prune out \"the\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space size (using TFIDF): (21802, 44045)\n",
      "  (0, 37883)\t0.18565385954834512\n",
      "  (0, 24659)\t0.2500345232367134\n",
      "  (0, 15226)\t0.25639046572035723\n",
      "  (0, 26660)\t0.17561152736960378\n",
      "  (0, 23985)\t0.1925927500306722\n",
      "  (0, 22991)\t0.16044767939535962\n",
      "  (0, 42083)\t0.18984640176982912\n",
      "  (0, 41365)\t0.1543207744837252\n",
      "  (0, 7246)\t0.14059126992943502\n",
      "  (0, 16261)\t0.1784628628725588\n",
      "  (0, 24454)\t0.12804387104621462\n",
      "  (0, 15223)\t0.26344567340807307\n",
      "  (0, 26105)\t0.14662061838154353\n",
      "  (0, 3761)\t0.09883064069307852\n",
      "  (0, 24586)\t0.1579972519146742\n",
      "  (0, 34418)\t0.22806178452645745\n",
      "  (0, 34040)\t0.1638445966736955\n",
      "  (0, 38468)\t0.13527781692615354\n",
      "  (0, 36044)\t0.34058106427217183\n",
      "  (0, 31309)\t0.2838666463265357\n",
      "  (0, 37689)\t0.06611242944726782\n",
      "  (0, 16331)\t0.16788221772423795\n",
      "  (0, 3989)\t0.29703234834833714\n",
      "  (0, 19715)\t0.1065038202170494\n",
      "  (0, 38395)\t0.2534685554135372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "tweets_tfidf = tfidf_vectorizer.fit_transform(tweets)\n",
    "\n",
    "print(\"Train feature space size (using TFIDF):\", tweets_tfidf.shape)\n",
    "print(tweets_tfidf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Links\n",
    "\n",
    "Some tweets have links to other websites or other tweets.\n",
    "Links can be identified by the appearance of the `https://t.co/` redirect service.\n",
    "\n",
    "This *numeric* feature will track the number of links in a single tweet. Linking could indicate some opinion is being stated on the linked text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "{0, 1, 2, 3, 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a list of number of redirects/links\n",
    "num_links = []\n",
    "\n",
    "for t in tweets:\n",
    "    links = re.findall(r\"https://t.co\", t)\n",
    "    num_links.append(len(links))\n",
    "\n",
    "# check the head and range of values for this\n",
    "print(num_links[:10])\n",
    "print(set(num_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hashtags\n",
    "Hashtags are used in twitter to link tweets with similar subjects together.\n",
    "Extracting these from the tweets may help in grouping similar tweets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#homeopathy'], [], [], [], [], ['#mtvstars'], ['#thisisus'], ['#orangetheworld', '#unitednations', '#unodc'], [], ['#nevereverquit']]\n"
     ]
    }
   ],
   "source": [
    "# create a list of hashtags in a tweet\n",
    "hashtags = []\n",
    "all_hashtags = set()\n",
    "\n",
    "for t in tweets:\n",
    "    hashes = re.findall(r\"#\\w+\", t)\n",
    "    hashtags.append(hashes)\n",
    "    all_hashtags = all_hashtags.union(hashes)\n",
    "\n",
    "# check the head and range of values for this\n",
    "print(hashtags[:10])\n",
    "# print(all_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. User References\n",
    "`@` symbols are used in twitter to reference a specific user.\n",
    "Extracting these from the tweets may help in grouping tweets with similar recipients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], ['@cbcnews'], [], [], ['@nbcthisisus'], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "# create a list of hashtags in a tweet\n",
    "references = []\n",
    "all_references = set()\n",
    "\n",
    "for t in tweets:\n",
    "    refs = re.findall(r\"@\\w+\", t)\n",
    "    references.append(refs)\n",
    "    all_references = all_references.union(refs)\n",
    "\n",
    "# check the head and range of values for this\n",
    "print(references[:10])\n",
    "# print(all_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Smiley Faces\n",
    "`ASCII` emoji such as `:)`, `:(`, `:P` can indicate emotion, leading to potentially easier judgment on the sentiment of a tweet.\n",
    "\n",
    "For the purposes of simplicity, emoji will be a combination of common eye symbols `;:B`, nose/middle symbols `',-` and mouth symbols `LlPp|\\/()VOo3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], []]\n",
      "{\":')\", ':--(', ':-o', ';)', ':-)', ':/', ';o', ':(', ':o', ':)', ':3', ':p', ':))', \":'(\", ';-)'}\n"
     ]
    }
   ],
   "source": [
    "# create a list of hashtags in a tweet\n",
    "emoticons = []\n",
    "all_emoticons = set()\n",
    "\n",
    "for t in tweets:\n",
    "    emotes = re.findall(r\"(?<=[ ^])[;:B]+[',-]*[LlPp\\|\\/()VOo3]+(?=[ $])\", t)\n",
    "    emoticons.append(emotes)\n",
    "    all_emoticons = all_emoticons.union(emotes)\n",
    "\n",
    "# check the head and range of values for this\n",
    "print(emoticons[:10])\n",
    "print(all_emoticons)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
